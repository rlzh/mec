{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shared import const\n",
    "from shared import utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "from gensim import models\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess, lemmatize\n",
    "from gensim.models import CoherenceModel, LdaModel, LdaMulticore\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "#matplotlib inline\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "#Choose Random forest for multiclass classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare stopwords\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words(\"english\")\n",
    "\n",
    "#for the purpose of emotion classification, we trim the words by extending stopwords:\n",
    "stop_words.extend([\"from\", \"re\", \"use\", \"day\", \"let\", \"get\",\"say\", \"know\", \"think\", \"love\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preproccesing\n",
    "\n",
    "#remove words fewer than 3 characters\n",
    "def remove_words(list2d_words, threshold = 3):\n",
    "    '''\n",
    "    return a 2d list of words\n",
    "    '''\n",
    "    words_more_than_3chars = []\n",
    "    for i in range(len(list2d_words)):\n",
    "        proc_sentence = []\n",
    "        for j in range(len(list2d_words[i])):\n",
    "            if len(list2d_words[i][j]) >= threshold:\n",
    "                proc_sentence.append(list2d_words[i][j])\n",
    "        words_more_than_3chars.append(proc_sentence)\n",
    "    return words_more_than_3chars\n",
    "        \n",
    "\n",
    "#remove stopwords\n",
    "#simple_preprocess will remove punctuations and unnecessary characters altogether\n",
    "def remove_stopwords(list2d_words):\n",
    "    return [[word for word in simple_preprocess(\" \".join(doc)) if word not in stop_words] for doc in list2d_words]\n",
    "\n",
    "#lemmatize: word in third person changed to first person, etc, and only keep the nouns, adj, verb, adv\n",
    "nlp = spacy.load('en', disable = ['parse', 'ner'])\n",
    "\n",
    "def my_lemmatize(list2d_words, allowed_postags = ['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in list2d_words:\n",
    "        doc = nlp(\" \".join(sent))\n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize each document into a list of words, removing punctuations and unnecessary characters altogether.\n",
    "def sentences_to_words(sentences):\n",
    "    yield(gensim.utils.simple_preprocess(str(sentences), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "import itertools\n",
    "\n",
    "def corpus_to_2d_words(corpus):\n",
    "    word_corpus = []\n",
    "    for i in range(len(corpus)):\n",
    "        data_words = list(sentences_to_words(corpus[i]))\n",
    "        word_corpus = [*word_corpus, *data_words]\n",
    "    return word_corpus\n",
    "\n",
    "def words_2d_to_dict(word_2d_list):\n",
    "    dictionary = corpora.Dictionary(word_2d_list)\n",
    "    return dictionary\n",
    "\n",
    "def df_to_lemmatized_words(df):\n",
    "    words_2d = corpus_to_2d_words(df)\n",
    "    words_morethan_3chars = remove_words(words_2d)\n",
    "    words_nostops = remove_stopwords(words_morethan_3chars)\n",
    "    lemmatized_words = my_lemmatize(words_nostops)\n",
    "    return lemmatized_words\n",
    "\n",
    "def lemmatized_to_corpus(words_2d):\n",
    "    dict_words = words_2d_to_dict(words_2d)\n",
    "    corpus = [dict_words.doc2bow(simple_preprocess(\" \".join(line))) for line in words_2d]\n",
    "    \n",
    "def build_LDA_model(dict_words, corpus):\n",
    "    lda_model = gensim.models.ldamodel.LdaModel(corpus = corpus,\n",
    "                                          id2word = dict_words,\n",
    "                                          num_topics = NUM_TOPICS, #tried 3, 4, 5, 6, 10 , 20. seems 3 for coherence is the best, the second is 4\n",
    "                                          random_state = 100, #the seed \n",
    "                                          update_every = 0, #batch mode\n",
    "                                          chunksize = 1000, #larger the heavier workload for the memory\n",
    "                                          passes = 10,#how to determine the chunksize and passes?relevant to size of dataset?\n",
    "                                          alpha = 'auto',\n",
    "                                          minimum_probability = 0.0,\n",
    "                                          per_word_topics = False #non-indicative words would be omitted\n",
    "                                          )\n",
    "    return lda_model\n",
    "    \n",
    "#evaluate by perplexity and coherence\n",
    "def print_coherence_perplexity(the_model, lemmatized_words, dict_words, corpus, f=None):\n",
    "    coherence_model = CoherenceModel(model = the_model, texts = lemmatized_words, dictionary = dict_words, coherence = 'c_v')\n",
    "    coherence_lda = coherence_model.get_coherence()\n",
    "    #compute model coherence: higher the better:\n",
    "    print('\\nCoherence Score: ', coherence_lda, file = f)\n",
    "    #compute model perplexity: lower the better:\n",
    "    print('\\nPerplexity: ', the_model.log_perplexity(corpus), file = f)\n",
    "    \n",
    "#get the LDA generated topic-document dataset and responding label for classification\n",
    "def generate_data(model, corpus):\n",
    "    topics_features = []\n",
    "    for i in range(len(corpus)):\n",
    "        row = []\n",
    "        for j in range(NUM_TOPICS):\n",
    "            row.append(model.get_document_topics(corpus[i])[j][1])\n",
    "        topics_features.append(row)\n",
    "    #generate data for supervised classification\n",
    "    print(\"length of topics_features is : {}\".format(len(topics_features)))\n",
    "    gen_df_mid = pd.DataFrame(topics_features)\n",
    "    return gen_df_mid\n",
    "\n",
    "def generate_train_test(X, Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "#z-score normalization\n",
    "def zscore_normalization(X_train, X_test):\n",
    "    zscoreScaler = StandardScaler().fit(X_train)\n",
    "    X_tr_std = zscoreScaler.transform(X_train)\n",
    "    X_ts_std = zscoreScaler.transform(X_test)\n",
    "    return X_tr_std, X_ts_std\n",
    "\n",
    "def RF_classify_score(X_tr_std, X_ts_std, y_train, y_test):\n",
    "    rf_clf = RandomForestClassifier()\n",
    "    rf_clf.fit(X_tr_std, y_train)\n",
    "    rf_pred = rf_clf.predict(X_ts_std)\n",
    "    score = accuracy_score(y_test, rf_pred)\n",
    "    print(score)\n",
    "    return score\n",
    "\n",
    "def complement_classify_score(X_train, X_test, y_train, y_test):\n",
    "    cnb = ComplementNB(alpha = 0.1)\n",
    "    cnb.fit(X_train, y_train)\n",
    "    cnb_pred = cnb.predict(X_test)\n",
    "    score = accuracy_score(y_test, cnb_pred)\n",
    "    print(score)\n",
    "    return score  \n",
    "    \n",
    "def randomForest_LDA(X, Y):\n",
    "    X1_train, X1_test, y1_train, y1_test = generate_train_test(X,Y)\n",
    "    #z-score normalization\n",
    "    X1_tr_std, X1_ts_std = zscore_normalization(X1_train, X1_test)\n",
    "    RF_classify_score(X1_tr_std, X1_ts_std, y1_train, y1_test)\n",
    "    \n",
    "def complementNB_LDA(X, Y):\n",
    "    X_train, X_test, y_train, y_test = generate_train_test(X,Y)\n",
    "    #X_tr_std, X_ts_std = zscore_normalization(X_train, X_test)\n",
    "    complement_classify_socre(X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the TF-IDF model\n",
    "def build_tfidf_model(corpus):\n",
    "    tfidf = models.TfidfModel(corpus, smartirs='ntc')\n",
    "    corpus_tfidf = tfidf[corpus]\n",
    "    return corpus_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of topics_features is : 4440\n"
     ]
    }
   ],
   "source": [
    " #use k-fold validation:\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "kFolder = KFold(n_splits = 10, shuffle = True) #10-fold cross-validation\n",
    "\n",
    "def kfold_classification(X, Y, clf, normalization_func = None, f = None):\n",
    "    sum_accuracy = []\n",
    "    for k, (train, test) in enumerate(kFolder.split(X, Y)):\n",
    "        X_train = np.array(X.iloc[train, :])\n",
    "        X_test = np.array(X.iloc[test, :])\n",
    "        y_train = np.array(Y.iloc[train])\n",
    "        #print(y_train.shape)\n",
    "        y_test = np.array(Y.iloc[test])\n",
    "        if normalization_func != None:\n",
    "            X_train, X_test = normalization_func(X_train, X_test)\n",
    "        #rf_clf = RandomForestClassifier()\n",
    "        clf.fit(X_train, y_train)\n",
    "        rf_pred = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, rf_pred)\n",
    "        sum_accuracy.append(accuracy)\n",
    "        #print(\"the {} th fold split got accuracy {}; f1-score: {} \".format(k, accuracy, f1_score(y_test, rf_pred)), file = f)\n",
    "    k_fold_avg = sum(sum_accuracy)/len(sum_accuracy)\n",
    "    print(\"the average of 10 rounds is {}\".format(k_fold_avg), file = f)\n",
    "    return k_fold_avg\n",
    "\n",
    "#plot topic distribution for each class: add up the sum of portion of each topic\n",
    "def plot_topics_per_class(df, gen_df_mid, caption):\n",
    "    pos = df[df['y'] == 1].index.values.astype(int)\n",
    "    topics = gen_df_mid_1.sum(axis = 0)\n",
    "\n",
    "    plot_x = [x+1 for x in range(gen_df_mid_1.shape[1])]\n",
    "    plt.plot(plot_x, topics)\n",
    "    plt.xlabel(\"topic ID\")\n",
    "    plt.ylabel(\"topic portion in the class\")\n",
    "    plt.savefig(caption + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_1.y.unique() is  [-1  1]\n",
      "length of y1 is : 4340\n",
      "length of y2 is : 3382\n",
      "length of dict_words_1 is : 19488\n",
      "length of corpus_1 is : 4340\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'f' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-302c4462be74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mlda_model_4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_LDA_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_words_4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---------------------start of topic # {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"-------------------\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mprint_coherence_perplexity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlda_model_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlemmatized_words_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_words_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_cc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'f' is not defined"
     ]
    }
   ],
   "source": [
    "#Build LDA model\n",
    "data_file = [const.CLEAN_UNEVEN_SPOTIFY, const.CLEAN_UNEVEN_DEEZER]\n",
    "for every in data_file:\n",
    "    name = str(every).split('/')[-1].split('.')[0]\n",
    "    f_topic = open('0405_topicno_' + name + '.txt', 'a')\n",
    "    f_cc = open('0405_coherence_accuracyScore_each' + name +'.txt', 'a')    \n",
    "    df_full = pd.read_csv(every)\n",
    "    #print(df_full.shape)        \n",
    "    df_1 = utils.get_class_based_data(df_full, 1, include_other_classes=True) #\n",
    "    #print(df_1.head(2))\n",
    "    print(\"df_1.y.unique() is \", df_1.y.unique())\n",
    "    df_2 = utils.get_class_based_data(df_full, 2, include_other_classes=True)\n",
    "    df_3 = utils.get_class_based_data(df_full, 3, include_other_classes=True)\n",
    "    df_4 = utils.get_class_based_data(df_full, 4, include_other_classes=True)\n",
    "\n",
    "    df_1.reset_index()\n",
    "    df_2.reset_index()\n",
    "    df_3.reset_index()\n",
    "    df_4.reset_index()\n",
    "    Y1 = df_1.iloc[:, -1]\n",
    "    print(\"length of y1 is :\", len(Y1))\n",
    "    Y2 = df_2.iloc[:, -1]\n",
    "    print(\"length of y2 is : {}\".format(len(Y2)))\n",
    "    Y3 = df_3.iloc[:, -1]\n",
    "    Y4 = df_4.iloc[:, -1]\n",
    "    train_dflist_1 = df_1.lyrics[:].tolist()\n",
    "    #print(\"length of train_dflist_1 is : {}\".format(len(train_dflist_1)))\n",
    "    train_dflist_2 = df_2.lyrics[:].tolist()\n",
    "    train_dflist_3 = df_3.lyrics[:].tolist()\n",
    "    train_dflist_4 = df_4.lyrics[:].tolist()\n",
    "    \n",
    "    lemmatized_words_1 = df_to_lemmatized_words(train_dflist_1)\n",
    "    #print(\"length of lemmatized_words_1 is : {}\".format(len(lemmatized_words_1)))\n",
    "    lemmatized_words_2 = df_to_lemmatized_words(train_dflist_2)\n",
    "    lemmatized_words_3 = df_to_lemmatized_words(train_dflist_3)\n",
    "    lemmatized_words_4 = df_to_lemmatized_words(train_dflist_4)\n",
    "\n",
    "    #print(lemmatized_words)\n",
    "\n",
    "    #turn the 2d word list to dict \n",
    "    dict_words_1 = words_2d_to_dict(lemmatized_words_1)\n",
    "    print(\"length of dict_words_1 is : {}\".format(len(dict_words_1)))\n",
    "    dict_words_2 = words_2d_to_dict(lemmatized_words_2)\n",
    "    dict_words_3 = words_2d_to_dict(lemmatized_words_3)\n",
    "    dict_words_4 = words_2d_to_dict(lemmatized_words_4)\n",
    "    #print(dict_words)\n",
    "\n",
    "    #there's 2 input for lDA: dictinary and the corpus\n",
    "    #create bag of words\n",
    "    corpus_1 =  [dict_words_1.doc2bow(simple_preprocess(\" \".join(line))) for line in lemmatized_words_1]\n",
    "    print(\"length of corpus_1 is : {}\".format(len(corpus_1)))\n",
    "    corpus_2 =  [dict_words_2.doc2bow(simple_preprocess(\" \".join(line))) for line in lemmatized_words_2]\n",
    "    corpus_3 =  [dict_words_3.doc2bow(simple_preprocess(\" \".join(line))) for line in lemmatized_words_3]\n",
    "    corpus_4 =  [dict_words_4.doc2bow(simple_preprocess(\" \".join(line))) for line in lemmatized_words_4]\n",
    "    for i in range(3, 9):\n",
    "        NUM_TOPICS = i\n",
    "        lda_model_1 = build_LDA_model(dict_words_1, corpus_1)\n",
    "        lda_model_2 = build_LDA_model(dict_words_2, corpus_2)\n",
    "\n",
    "        lda_model_3 = build_LDA_model(dict_words_3, corpus_3)\n",
    "\n",
    "        lda_model_4 = build_LDA_model(dict_words_4, corpus_4)\n",
    "        print(\"---------------------start of topic # {}\".format(i), \"-------------------\", file = f)\n",
    "        print_coherence_perplexity(lda_model_1, lemmatized_words_1, dict_words_1, corpus_1, file = f_cc)\n",
    "    \n",
    "        print_coherence_perplexity(lda_model_2, lemmatized_words_2, dict_words_2, corpus_2, file = f_cc)\n",
    "\n",
    "        print_coherence_perplexity(lda_model_3, lemmatized_words_3, dict_words_3, corpus_3, file = f_cc)\n",
    "\n",
    "        print_coherence_perplexity(lda_model_4, lemmatized_words_4, dict_words_4, corpus_4, file = f_cc)\n",
    "\n",
    "        gen_df_mid_1 = generate_data(lda_model_1, corpus_1)\n",
    "        print(\"length of gen_df_mid_1[0] is : {}\".format(len(gen_df_mid_1[0])))\n",
    "        print(gen_df_mid_1.head())\n",
    "        gen_df_mid_2 = generate_data(lda_model_2, corpus_2)\n",
    "        gen_df_mid_3 = generate_data(lda_model_3, corpus_3)\n",
    "        gen_df_mid_4 = generate_data(lda_model_4, corpus_4)\n",
    "        captions = ['topics of class '+x for x in range(4)]\n",
    "        plot_topics_per_class(df_1, gen_df_mid_1, captions[0])\n",
    "        plot_topics_per_class(df_2, gen_df_mid_2, captions[1])\n",
    "        plot_topics_per_class(df_3, gen_df_mid_3, captions[2])\n",
    "        plot_topics_per_class(df_4, gen_df_mid_4, captions[3])\n",
    "    #randomForest_LDA(gen_df_mid_1, df_1.iloc[:TRAIN_SAMPLE, -1])\n",
    "\n",
    "    #kfold for class 1:\n",
    "        print(\"random forest classificaton:\", f_cc)\n",
    "        rf_clf = RandomForestClassifier()\n",
    "        rf_score_sum = kfold_classification(gen_df_mid_1, Y1, rf_clf, zscore_normalization, f_cc)\n",
    "    \n",
    "    #randomForest_LDA(gen_df_mid_2, df_2.iloc[:TRAIN_SAMPLE, -1])\n",
    "    #kfold for class 2:\n",
    "    #random forest classificaton:\n",
    "        rf_clf = RandomForestClassifier()\n",
    "        rf_score_sum = rf_score_sum + kfold_classification(gen_df_mid_2, Y2, rf_clf, zscore_normalization, f_cc)\n",
    "    \n",
    "    #randomForest_LDA(gen_df_mid_3, df_3.iloc[:TRAIN_SAMPLE, -1])\n",
    "    #kfold for class 3:\n",
    "    #random forest classificaton:\n",
    "        rf_clf = RandomForestClassifier()\n",
    "        rf_score_sum = rf_score_sum + kfold_classification(gen_df_mid_3, Y3, rf_clf, zscore_normalization, f_cc)\n",
    "    \n",
    "    #randomForest_LDA(gen_df_mid_4, df_4.iloc[:TRAIN_SAMPLE, -1])\n",
    "    #kfold for class 4:\n",
    "    #random forest classificaton:\n",
    "        rf_clf = RandomForestClassifier()\n",
    "        rf_score_sum = rf_score_sum + kfold_classification(gen_df_mid_4, Y4, rf_clf, zscore_normalization, f_cc)\n",
    "        rf_score_avg = rf_score_sum / 4\n",
    "        print(\"topics: {}, RF score average of 4 models: {}\".format(i, rf_score_avg), file = f)\n",
    "\n",
    "        print(\"complement naive bayes classifier:\", f_cc)\n",
    "        cnb_clf = ComplementNB(alpha= 0.1)\n",
    "        cnb_score_sum = kfold_classification(gen_df_mid_1, Y1, cnb_clf, None, f_cc)\n",
    "    \n",
    "    #complement naive bayes classifier:\n",
    "        cnb_clf = ComplementNB(alpha= 0.1)\n",
    "        cnb_score_sum = cnb_score_sum + kfold_classification(gen_df_mid_2, Y2, cnb_clf, None, f_cc)\n",
    "\n",
    "    #complement naive bayes classifier:\n",
    "        cnb_clf = ComplementNB(alpha= 0.1)\n",
    "        cnb_score_sum = cnb_score_sum + kfold_classification(gen_df_mid_3, Y3, cnb_clf, None, f_cc)\n",
    "    \n",
    "    #complement naive bayes classifier:\n",
    "        cnb_clf = ComplementNB(alpha= 0.1)\n",
    "        cnb_score_sum = cnb_score_sum + kfold_classification(gen_df_mid_4, Y4, cnb_clf, None, f_cc)\n",
    "        cnb_score_avg = cnb_score_sum / 4\n",
    "        print(\"Complement NB score average of 4 models: {}\".format(cnb_score_avg), file = f)\n",
    "        \n",
    "        #kfold for class 1:\n",
    "        print(\"KNN classificaton:\", f_cc)\n",
    "        knn_clf = KNeighborsClassifier(n_neighbors)\n",
    "        knn_score_sum = kfold_classification(gen_df_mid_1, Y1, knn_clf, zscore_normalization, f_cc)\n",
    "    \n",
    "        #randomForest_LDA(gen_df_mid_2, df_2.iloc[:TRAIN_SAMPLE, -1])\n",
    "        #kfold for class 2:\n",
    "  \n",
    "        knn_clf = KNeighborsClassifier(n_neighbors)\n",
    "        knn_score_sum = knn_score_sum + kfold_classification(gen_df_mid_2, Y2, knn_clf, zscore_normalization, f_cc)\n",
    "    \n",
    "    \n",
    "        #kfold for class 3:\n",
    "        knn_clf = KNeighborsClassifier(n_neighbors)\n",
    "        knn_score_sum = knn_score_sum + kfold_classification(gen_df_mid_3, Y3, knn_clf, zscore_normalization, f_cc)\n",
    "    \n",
    "    \n",
    "        #kfold for class 4:\n",
    "        rf_clf = RandomForestClassifier()\n",
    "        knn_clf = KNeighborsClassifier(n_neighbors)\n",
    "        knn_score_sum = knn_score_sum + kfold_classification(gen_df_mid_4, Y4, knn_clf, zscore_normalization, f_cc)\n",
    "    \n",
    "        knn_score_avg = knn_score_sum / 4\n",
    "        print(\"topics: {}, KNN score average of 4 models: {}\".format(i, knn_score_avg), file = f)\n",
    "        print(\"---------------------end of topic # {}\".format(i), \"-------------------\", file = f)\n",
    "        f.flush()\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the best k for KNN\n",
    "\n",
    "#read data\n",
    "data_file = [const.CLEAN_UNEVEN_SPOTIFY, const.CLEAN_UNEVEN_DEEZER]\n",
    "for every in data_file:\n",
    "    df_full = pd.read_csv(every)\n",
    "    print(df_full.shape)\n",
    "    df_1 = utils.get_class_based_data(df_full, 1, limit_size = True) \n",
    "    df_2 = utils.get_class_based_data(df_full, 2, limit_size = True)\n",
    "    df_3 = utils.get_class_based_data(df_full, 3, limit_size = True)\n",
    "    df_4 = utils.get_class_based_data(df_full, 4, limit_size = True)\n",
    "    df_1.reset_index()\n",
    "    df_2.reset_index()\n",
    "    df_3.reset_index()\n",
    "    df_4.reset_index()\n",
    "    TRAIN_SAMPLE = int(len(df_1))\n",
    "    Y1 = df_1.iloc[:TRAIN_SAMPLE, -1]\n",
    "    Y2 = df_2.iloc[:TRAIN_SAMPLE, -1]\n",
    "    Y3 = df_3.iloc[:TRAIN_SAMPLE, -1]\n",
    "    Y4 = df_4.iloc[:TRAIN_SAMPLE, -1]\n",
    "    train_dflist_1 = df_1.lyrics[:TRAIN_SAMPLE].tolist()\n",
    "    train_dflist_2 = df_2.lyrics[:TRAIN_SAMPLE].tolist()\n",
    "    train_dflist_3 = df_3.lyrics[:TRAIN_SAMPLE].tolist()\n",
    "    train_dflist_4 = df_4.lyrics[:TRAIN_SAMPLE].tolist()\n",
    "\n",
    "    lemmatized_words_1 = df_to_lemmatized_words(train_dflist_1)\n",
    "    lemmatized_words_2 = df_to_lemmatized_words(train_dflist_2)\n",
    "    lemmatized_words_3 = df_to_lemmatized_words(train_dflist_3)\n",
    "    lemmatized_words_4 = df_to_lemmatized_words(train_dflist_4)\n",
    "\n",
    "    #print(lemmatized_words)\n",
    "\n",
    "    #turn the 2d word list to dict \n",
    "    dict_words_1 = words_2d_to_dict(lemmatized_words_1)\n",
    "    dict_words_2 = words_2d_to_dict(lemmatized_words_2)\n",
    "    dict_words_3 = words_2d_to_dict(lemmatized_words_3)\n",
    "    dict_words_4 = words_2d_to_dict(lemmatized_words_4)\n",
    "    #print(dict_words)\n",
    "\n",
    "    #there's 2 input for lDA: dictinary and the corpus\n",
    "    #create bag of words\n",
    "    corpus_1 =  [dict_words_1.doc2bow(simple_preprocess(\" \".join(line))) for line in lemmatized_words_1]\n",
    "    corpus_2 =  [dict_words_2.doc2bow(simple_preprocess(\" \".join(line))) for line in lemmatized_words_2]\n",
    "    corpus_3 =  [dict_words_3.doc2bow(simple_preprocess(\" \".join(line))) for line in lemmatized_words_3]\n",
    "    corpus_4 =  [dict_words_4.doc2bow(simple_preprocess(\" \".join(line))) for line in lemmatized_words_4]\n",
    "\n",
    "    name = str(every).split('/')[-1].split('.')[0]\n",
    "    f = open('knn_'+ name +'count.txt', 'a')\n",
    "    #highest score is gotten when number of topics is 6.\n",
    "    NUM_TOPICS = 6\n",
    "    for i in range(2, 20):\n",
    "        n_neighbors = i\n",
    "        lda_model_1 = build_LDA_model(dict_words_1, corpus_1)\n",
    "        lda_model_2 = build_LDA_model(dict_words_2, corpus_2)\n",
    "\n",
    "        lda_model_3 = build_LDA_model(dict_words_3, corpus_3)\n",
    "\n",
    "        lda_model_4 = build_LDA_model(dict_words_4, corpus_4)\n",
    "        print(\"---------------------start of topic # {}\".format(i), \"-------------------\", file = f)\n",
    "   \n",
    "        gen_df_mid_1 = generate_data(lda_model_1, corpus_1)\n",
    "        gen_df_mid_2 = generate_data(lda_model_2, corpus_2)\n",
    "        gen_df_mid_3 = generate_data(lda_model_3, corpus_3)\n",
    "        gen_df_mid_4 = generate_data(lda_model_4, corpus_4)\n",
    "\n",
    "        #randomForest_LDA(gen_df_mid_1, df_1.iloc[:TRAIN_SAMPLE, -1])\n",
    "\n",
    "        #kfold for class 1:\n",
    "        print(\"KNN classificaton:\")\n",
    "        knn_clf = KNeighborsClassifier(n_neighbors)\n",
    "        knn_score_sum = kfold_classification(gen_df_mid_1, Y1, knn_clf, zscore_normalization)\n",
    "    \n",
    "        #randomForest_LDA(gen_df_mid_2, df_2.iloc[:TRAIN_SAMPLE, -1])\n",
    "        #kfold for class 2:\n",
    "  \n",
    "        knn_clf = KNeighborsClassifier(n_neighbors)\n",
    "        knn_score_sum = knn_score_sum + kfold_classification(gen_df_mid_2, Y2, knn_clf, zscore_normalization)\n",
    "    \n",
    "\n",
    "        #kfold for class 3:\n",
    "        knn_clf = KNeighborsClassifier(n_neighbors)\n",
    "        knn_score_sum = knn_score_sum + kfold_classification(gen_df_mid_3, Y3, knn_clf, zscore_normalization)\n",
    "    \n",
    "    \n",
    "        #kfold for class 4:\n",
    "        rf_clf = RandomForestClassifier()\n",
    "        knn_clf = KNeighborsClassifier(n_neighbors)\n",
    "        knn_score_sum = knn_score_sum + kfold_classification(gen_df_mid_4, Y4, knn_clf, zscore_normalization)\n",
    "    \n",
    "        knn_score_avg = knn_score_sum / 4\n",
    "        print(\"topics: {}, KNN score average of 4 models: {}\".format(i, knn_score_avg), file = f)\n",
    "   \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several parameters to adjust:\n",
    "\n",
    "the number of topics;\n",
    "\n",
    "alpha and beta: hyperparameter that affect sparsity of the topics. Default to 1.0/num_topics\n",
    "\n",
    "chunksize: the number of documents to be used in each training chunk\n",
    "\n",
    "update_every: how often the model parameters should be updated\n",
    "\n",
    "passes: the total number of training passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the TF-IDF model \n",
    "def lda_tfidf_ize_(corpus_list, dict_words_list):\n",
    "    corpus_tfidf_list = []\n",
    "    lda_tfidf_model_list = []\n",
    "    for corpus, dict_words in map(corpus_list, dict_words_list):\n",
    "        corpus_tfidf_list.append(build_tfidf_model(corpus_1))\n",
    "        lda_tfidf_model_list.append(dict_words, corpus_tfidf_list[-1])\n",
    "    return corpus_tfidf_list, lda_tfidf_model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize the topics\n",
    "\n",
    "# pyLDAvis.enable_notebook()\n",
    "# vis = pyLDAvis.gensim.prepare(lda_model_1, corpus_1, dict_words_1)\n",
    "# vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to infer pyLDAvis's output?\n",
    "\n",
    "Each bubble represents a topic. The larger the bubble, the more prevalent is that topic.\n",
    "\n",
    "A good topic model will have fairly big, non-overlapping bubbles scattered throughout the chart instead of being clustered in one quadrant.\n",
    "\n",
    "A model with too many topics, will typically have many overlaps, small sized bubbles, clustered in one region of the chart\n",
    "\n",
    "So this model ... maybe use fewer number of topics\n",
    "\n",
    "You could determine the number of topics using prior knowledge of the number of natural topics in the document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As we can see that after applying tf-idf model as the corpus input, the cohenrence score increased by 0.01, while the classification score decreased by 0.15."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve upon this model by using Mallet's version of LDA algorithm, which always gives a better quality of topics than Gensim's inbuilt version of the LDA algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use mallet's implementation of LDA\n",
    "def mallet_lda(lemmatized_words, corpus1, dict_words_1, NUM_TOPICS):\n",
    "    mallet_path = \"../mallet-2.0.8/bin/mallet\"\n",
    "    ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus_1, num_topics=NUM_TOPICS, id2word=dict_words_1)\n",
    "    # evaluate the mallet model: Compute Coherence Score\n",
    "    coherence_model = CoherenceModel(model = ldamallet, texts = lemmatized_words_1, dictionary = dict_words_1, coherence = 'c_v')\n",
    "    coherence_lda = coherence_model.get_coherence()\n",
    "    print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try tf-idf on mallet\n",
    "def mallet_LDA_tfidf(mallet_path, lemmatized_words_1, corpus_tfidf_1, dict_words_1, NUM_TOPICS):\n",
    "    ldamallet_tfidf = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus_tfidf_1, num_topics=NUM_TOPICS, id2word=dict_words_1)\n",
    "    # evaluate the mallet model: Compute Coherence Score\n",
    "    coherence_model = CoherenceModel(model = ldamallet_tfidf, texts = lemmatized_words_1, dictionary = dict_words_1, coherence = 'c_v')\n",
    "    coherence_lda = coherence_model.get_coherence()\n",
    "    print('\\nCoherence Score: ', coherence_lda)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
